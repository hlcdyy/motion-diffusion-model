{
    // 使用 IntelliSense 了解相关属性。 
    // 悬停以查看现有属性的描述。
    // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [

        {
            "name": "Python: creat_init_inpainting_style_model",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "train.resume_model_parameters", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--model_path",
                // "save/my_inpainting_style_model/model000000000.pt",
                // "save_bandai/my_inpainting_style_model_regularization_ddim20/model000000000.pt",
                // "save_stylexia/my_inpainting_style_model/350angry_jumping/model000000000.pt"
                // "save_bandai_train/my_inpainting_style_model/dataset-2_raise-up-both-hands_masculine_021/model000000000.pt"
                // "save_AIST/my_inpainting_style_model/gJS_sBM_cAll_d01_mJS3_ch02/model000000000.pt"
                "save_bandai_train_newtpose/my_inpainting_style_model/dataset-2_raise-up-left-hand_masculine_003/model000000000.pt"
    
            ]
        },
        {
            "name": "Python: creat_init_inpainting_model",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "train.resume_model_parameters", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--model_path",
                "save/my_inpainting_model/model000000000.pt",
            ]
        },
        {
            "name": "Python: creat_init_transfer_module",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "train.resume_model_parameters", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--transfer_module_path",
                "save/my_style_transfer_module_zero/model000000000.pt",
                "--zero_conv",
    
            ]
        },
        {
            "name": "Python: creat_init_stylediffusion_module",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "train.resume_model_parameters", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--transfer_module_path",
                "save/my_style_diffusion/model000000000.pt",
                "--inpainting_mask",
                "root_horizontal",
    
            ]
        },
        {
            "name": "Python: learned_diffusion_transfer_in_clipspace",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "sample.style_diffusion_transfer_module", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--transfer_module_path",
                "save/my_style_diffusion/model_pretrained.pt",
                "--num_samples",
                "5",
                "--seed",
                "10",
                "--inpainting_mask",
                "root_horizontal", 
            ]
        },
        {
            "name": "Python: learned_transfer_in_clipspace",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "sample.style_transfer_module", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--transfer_module_path",
                // "save/my_style_transfer_module_zero/model_pretrained.pt",
                "save/my_style_transfer_module_zero/model000102261.pt",
                "--num_samples",
                "5",
                "--seed",
                "1243",
                "--zero_conv",
            ]
        },
        {
            "name": "Python: residual_transfer_in_clipspace",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "sample.new_style_transfer_residual", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--motionenc_path",
                // "save/my_motion_enc_512_finetune_encmdm_bandai-2_addtextloss/model000620161.pt",
                "save/my_motion_enc_512_finetune_encmdm_bandai-2_addtextloss/model000680161.pt",
                "--num_samples",
                "5",
                "--seed",
                "1243"
            ]
        },
        {
            "name": "Python: adain_transfer_in_clipspace",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "sample.new_style_transfer_adain", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--motionenc_path",
                "save/my_motion_enc_512_finetune_encmdm_bandai-2/model000600161.pt",
                "--num_samples",
                "5",
                "--seed",
                "1243"
            ]
        },

        {
            "name": "Python: train_dis_stylexia_for_ablation",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "train.train_discriminator_for_ablation",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                "save_stylexia_ablation_dis/",
                "--dataset",
                "stylexia_posrot",
                "--overwrite",
                "--train_platform_type",
                "TensorboardPlatform",
                "--num_steps",
                "4_500",
                "--save_interval",
                "2_000",
                "--log_interval",
                "500"
            ]
        },
        {
            "name": "Python: train_ae_stylexia_for_ablation",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "train.train_ae_for_ablation",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                "save_stylexia_ablation/",
                "--dataset",
                "stylexia_posrot",
                "--overwrite",
                "--train_platform_type",
                "TensorboardPlatform",
                "--num_steps",
                "4_500",
                "--save_interval",
                "2_000",
                "--log_interval",
                "500"
            ]
        },

        {
            "name": "Python: train_motion_encoder_bandai",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "train.train_motion_encoder",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                // "save_bandai/my_motion_enc_512",
                // "save_bandai_train/my_motion_enc_512",
                "save_bandai_train_newtpose/my_motion_enc_512",
                "--dataset",
                "bandai-2_posrot",
                "--overwrite",
                "--train_platform_type",
                "TensorboardPlatform",
                // "--resume_checkpoint",
                // "save/my_motion_enc_512"
                "--num_steps",
                "4_500",
                "--save_interval",
                "2_000",
                "--log_interval",
                "500",
                "--mdm_path",
                // "./save_bandai/my_inpainting_model_new/model000100000.pt"
                // "./save_bandai_train/my_inpainting_model_new/model000100000.pt"
                "./save_bandai_train_newtpose/my_inpainting_model/model000100000.pt"


            ]
        },

        {
            "name": "Python: train_motion_encoder_stylexia",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "train.train_motion_encoder",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                "save_stylexia/my_motion_enc_512",
                "--dataset",
                "stylexia_posrot",
                "--overwrite",
                "--train_platform_type",
                "TensorboardPlatform",
                // "--resume_checkpoint",
                // "save/my_motion_enc_512"
                "--num_steps",
                "4_500",
                "--save_interval",
                "2_000",
                "--log_interval",
                "500",
                "--mdm_path",
                "./save_stylexia/my_inpainting_model/model000050000.pt"
            ]
        },
        {
            "name": "Python: train_motion_encoder_AIST",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "train.train_motion_encoder",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                "save_AIST/my_motion_enc_512",
                "--dataset",
                "AIST_posrot",
                "--overwrite",
                "--train_platform_type",
                "TensorboardPlatform",
                // "--resume_checkpoint",
                // "save/my_motion_enc_512"
                "--num_steps",
                "4_500",
                "--save_interval",
                "2_000",
                "--log_interval",
                "500",
                "--mdm_path",
                "./save_AIST/my_inpainting_model/model000100000.pt"
            ]
        },

        {
            "name": "Python: train_my_t2m_on_bandai",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "train.train_mdm", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                // "save_bandai/my_t2m_model_16diffsteps",
                "save_bandai_train/my_t2m_model",
                "--dataset",
                "bandai-2_posrot",
                "--overwrite",
                "--num_steps",
                "100_000",
                "--save_interval",
                "10_000",
                "--lr",
                "1e-4",
                "--train_platform_type",
                "TensorboardPlatform",
                "--log_interval",
                "500",     
                "--diffusion_steps",
                // "16",
                "1000"
            ]
        },

        {
            "name": "Python: train_my_root_horizontal_model_on_stylexia_fromscratch",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "train.train_root_horizontal_model_fromscratch", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                "save_stylexia/my_inpainting_model",
                "--dataset",
                "stylexia_posrot",
                "--overwrite",
                "--num_steps",
                "100_000",
                "--save_interval",
                "10_000",
                "--lr",
                "1e-4",
                "--train_platform_type",
                "TensorboardPlatform",
                "--log_interval",
                "500",    
                "--inpainting_mask",
                "root_horizontal", 
                "--diffusion_steps",
                "1000"
            ]
        },
        {
            "name": "Python: train_my_root_horizontal_model_on_AIST_fromscratch",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "train.train_root_horizontal_model_fromscratch", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                "save_AIST/my_inpainting_model",
                "--dataset",
                "AIST_posrot",
                "--overwrite",
                "--num_steps",
                "100_000",
                "--save_interval",
                "10_000",
                "--lr",
                "1e-4",
                "--train_platform_type",
                "TensorboardPlatform",
                "--log_interval",
                "500",    
                "--inpainting_mask",
                "root_horizontal", 
                "--diffusion_steps",
                "1000"
            ]
        },

        {
            "name": "Python: train_my_root_horizontal_model_on_bandai_fromscratch",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "train.train_root_horizontal_model_fromscratch", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                // "save_bandai/my_inpainting_model_16diffsteps",
                // "save_bandai_train/my_inpainting_model_new",
                "save_bandai_train_newtpose/my_inpainting_model",
                "--dataset",
                "bandai-2_posrot",
                "--overwrite",
                "--num_steps",
                "100_000",
                "--save_interval",
                "10_000",
                "--lr",
                "1e-4",
                "--train_platform_type",
                "TensorboardPlatform",
                "--log_interval",
                "500",    
                "--inpainting_mask",
                "root_horizontal", 
                "--diffusion_steps",
                // "16"
                "1000"
            ]
        },

        {
            "name": "Python: finetune_my_diffusion_style_model_video",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "train.finetune_style_diffusion_from_video", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                "save/my_inpainting_style_model_regularization_ddim20",
                "--dataset",
                "humanml",
                "--overwrite",
                "--num_steps",
                "100",
                "--save_interval",
                "300",
                "--lr",
                "1e-4",
                "--train_platform_type",
                "TensorboardPlatform",
                "--resume_checkpoint",
                "save/my_inpainting_style_model_regularization_cliptext/model_pretrained.pt",
                "--log_interval",
                "10",    
                "--inpainting_mask",
                "root_horizontal", 
                // "linear_vel",
                "--diffusion_steps",
                "1000",
                "--skip_steps",
                "700",
                "--batch_size",
                "64",
                "--weakly_style_pair",
                // "1",
                "0",
                "--Ls",
                "0.01",
                "--use_ddim",
                "1"
            ]
        },
        
        {
            "name": "Python: finetune_my_diffusion_style_model_stylexia",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "train.finetune_style_diffusion", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                // "save/my_inpainting_style_model_regularization_cliptext",
                // "save_bandai/my_inpainting_style_model_regularization_clipspace_ddim20",
                "save_stylexia/my_inpainting_style_model", 
                "--dataset",
                "stylexia_posrot",
                "--overwrite",
                "--num_steps",
                "24",
                "--save_interval",
                "100",
                "--lr",
                "1e-4",
                "--train_platform_type",
                "TensorboardPlatform",
                "--resume_checkpoint",
                "save_stylexia/my_inpainting_style_model/model_pretrained.pt",
                "--log_interval",
                "1",    
                "--inpainting_mask",
                "root_horizontal", 
                "--diffusion_steps",
                "1000",
                "--skip_steps",
                "700",
                "--batch_size",
                "64",
                "--weakly_style_pair",
                "1",
                // "0",
                "--use_ddim",
                "1",
                "--mdm_path",
                "./save_stylexia/my_inpainting_model/model000050000.pt",
                "--motion_enc_path",
                "./save_stylexia/my_motion_enc_512/model000004504.pt",
                "--inpainting_model_path", 
                "mdm_model is inpainting_model in this case.",
                "--style_file",
                // "350angry_jumping.npy"
                // "012strutting_normal walking.npy"
                // "001angry_normal walking.npy",
                "040depressed_normal walking.npy",
             

            ]
        },
        {
            "name": "Python: finetune_my_diffusion_style_model_bandai",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "train.finetune_style_diffusion", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                // "save/my_inpainting_style_model_regularization_cliptext",
                // "save_bandai/my_inpainting_style_model_regularization_clipspace_ddim20",
                // "save_bandai/my_inpainting_style_model",
                // "save_bandai_train/my_inpainting_style_model", 
                "save_bandai_train_newtpose/my_inpainting_style_model", 
                "--dataset",
                "bandai-2_posrot",
                "--overwrite",
                "--num_steps",
                "90",
                "--save_interval",
                "45",
                "--lr",
                "1e-4",
                "--train_platform_type",
                "TensorboardPlatform",
                "--resume_checkpoint",
                // "save_bandai/my_inpainting_style_model_regularization_ddim20/model_pretrained.pt",
                // "save_bandai_train/my_inpainting_style_model/model_pretrained.pt",
                "save_bandai_train_newtpose/my_inpainting_style_model/model_pretrained.pt",
                "--log_interval",
                "10",    
                "--inpainting_mask",
                "root_horizontal", 
                "--diffusion_steps",
                "1000",
                "--skip_steps",
                "700",
                "--batch_size",
                "64",
                "--weakly_style_pair",
                "1",
                // "0",
                "--use_ddim",
                "1",
                "--mdm_path",
                // "./save_bandai/my_inpainting_model_new/model000100000.pt",
                // "./save_bandai_train/my_inpainting_model_new/model000100000.pt",
                "./save_bandai_train_newtpose/my_inpainting_model/model000100000.pt",
                "--motion_enc_path",
                // "./save_bandai/my_motion_enc_512/model000004545.pt",
                // "./save_bandai_train/my_motion_enc_512/model000004545.pt",
                "./save_bandai_train_newtpose/my_motion_enc_512/model000004522.pt",
                "--inpainting_model_path", 
                "mdm_model is inpainting_model in this case.",
                "--style_file",
                // "dataset-2_raise-up-both-hands_masculine_021.npy"
                // "dataset-2_raise-up-left-hand_masculine_003.npy",
                // "dataset-2_walk-turn-left_exhausted_010.npy",
                // "dataset-2_walk_youthful_001.npy",
                // "dataset-2_run_exhausted_015.npy",
                "dataset-2_run_elderly_006.npy",
                "--Ls",
                "10",
            ]
        },
        {
            "name": "Python: finetune_my_diffusion_style_model_AIST",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "train.finetune_style_diffusion", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                "save_AIST/my_inpainting_style_model", 
                "--dataset",
                "AIST_posrot",
                "--overwrite",
                "--num_steps",
                "10",
                "--save_interval",
                "80",
                "--lr",
                "1e-4",
                "--train_platform_type",
                "TensorboardPlatform",
                "--resume_checkpoint",
                "save_AIST/my_inpainting_style_model/model_pretrained.pt",
                "--log_interval",
                "1",    
                "--inpainting_mask",
                "root_horizontal", 
                "--diffusion_steps",
                "1000",
                "--skip_steps",
                "700",
                "--batch_size",
                "64",
                "--weakly_style_pair",
                "1",
                // "0",
                "--use_ddim",
                "1",
                "--mdm_path",
                "./save_AIST/my_inpainting_model/model000100000.pt",
                "--motion_enc_path",
                "./save_AIST/my_motion_enc_512/model000004575.pt",
                "--inpainting_model_path", 
                "mdm_model is inpainting_model in this case.",
                "--style_file",
                "gJS_sBM_cAll_d01_mJS3_ch02.npy",
                "--Ls",
                "10",
            ]
        },

        {
            "name": "Python: finetune_my_diffusion_style_model",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "train.finetune_style_diffusion", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                // "save/my_inpainting_style_model_regularization_cliptext",
                "save/my_inpainting_style_model_regularization_ddim20",
                "--dataset",
                "humanml",
                "--overwrite",
                "--num_steps",
                "800",
                "--save_interval",
                "700",
                "--lr",
                "1e-4",
                "--train_platform_type",
                "TensorboardPlatform",
                "--resume_checkpoint",
                "save/my_inpainting_style_model_regularization_cliptext/model_pretrained.pt",
                "--log_interval",
                "10",    
                "--inpainting_mask",
                "root_horizontal", 
                "--diffusion_steps",
                "1000",
                "--skip_steps",
                "700",
                "--batch_size",
                "64",
                "--weakly_style_pair",
                // "1"
                "0",
                "--use_ddim",
                "1",
                "--Ls",
                "0",
                "--style_file",
                // "012581.npy"
                // "M002980.npy"
                // "M013056.npy"
                "M008551.npy"
            ]
        },
        {
            "name": "Python: finetune_my_diffusion_style_stylexia_unseen",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "train.finetune_style_diffusion_stylexia_unseen", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                "save/my_inpainting_style_model_regularization_ddim20",
                "--dataset",
                "humanml",
                "--overwrite",
                "--num_steps",
                "100",
                "--save_interval",
                "700",
                "--lr",
                "1e-4",
                "--train_platform_type",
                "TensorboardPlatform",
                "--resume_checkpoint",
                "save/my_inpainting_style_model_regularization_cliptext/model_pretrained.pt",
                "--log_interval",
                "10",    
                "--inpainting_mask",
                "root_horizontal", 
                "--diffusion_steps",
                "1000",
                "--skip_steps",
                "700",
                "--batch_size",
                "64",
                "--weakly_style_pair",
                "1",
                // "0",
                "--use_ddim",
                "1",
                "--Ls",
                "0.5",
                "--style_file",
                // "021old_normal walking.npy"
                // "025proud_normal walking.npy",
                "047sexy_normal walking.npy"
                // "482angry_kicking.npy"
                // "286depressed_running.npy",
                // "042depressed_normal walking.npy"
                // "355childlike_jumping.npy"
                // "007childlike_normal walking.npy"
            ]
        },
        {
            "name": "Python: train_my_root_horizontal_model",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "train.finetune_root_horizontal_model", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                "save/my_inpainting_model",
                "--dataset",
                "humanml",
                "--overwrite",
                "--num_steps",
                "80_000",
                "--save_interval",
                "10_000",
                "--lr",
                "1e-4",
                "--train_platform_type",
                "TensorboardPlatform",
                "--resume_checkpoint",
                "save/my_inpainting_model/model_pretrained.pt",
                "--log_interval",
                "1_000",    
                "--inpainting_mask",
                "root_horizontal", 
                "--diffusion_steps",
                "1000"
            ]
        },
        {
            "name": "Python: train_my_linear_vel_inpainting_model",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "train.finetune_root_horizontal_model", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                "save/my_linear_vel_inpainting_model",
                "--dataset",
                "humanml",
                "--overwrite",
                "--num_steps",
                "80_000",
                "--save_interval",
                "10_000",
                "--lr",
                "1e-4",
                "--train_platform_type",
                "TensorboardPlatform",
                "--resume_checkpoint",
                "save/my_inpainting_model/model_pretrained.pt",
                "--log_interval",
                "1_000",    
                "--inpainting_mask",
                // "root_horizontal", 
                "linear_vel",
                "--diffusion_steps",
                "1000"
            ]
        },

        {
            "name": "Python: train_my_style_diffusion",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "train.train_transfer_diffusion_module", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                "save/my_style_diffusion",
                "--dataset",
                "humanml",
                "--style_dataset",
                "bandai-2",
                "--overwrite",
                "--num_steps",
                "8_000",
                "--save_interval",
                "1_000",
                "--lr",
                "1e-4",
                "--train_platform_type",
                "TensorboardPlatform",
                "--resume_checkpoint",
                "save/my_style_diffusion/model_pretrained.pt",
                "--log_interval",
                "100",
                "--inpainting_mask",
                "root_horizontal", 
                "--diffusion_steps",
                "1000"

            ]
            
        },
        {
            "name": "Python: train_my_transfer_module_zero",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "train.train_transfer_module", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                "save/my_style_transfer_module_zero",
                "--dataset",
                "humanml",
                "--style_dataset",
                "bandai-2",
                "--overwrite",
                "--num_steps",
                "8_000",
                "--save_interval",
                "1_000",
                "--lr",
                "1e-4",
                "--train_platform_type",
                "TensorboardPlatform",
                "--zero_conv", 
                "--resume_checkpoint",
                "save/my_style_transfer_module_zero/model_pretrained.pt",
                "--lambda_bone",
                "0.1",
                "--log_interval",
                "100"

            ]
            
        },
        {
            "name": "Python: train_my_transfer_module_zero_lambda_1",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "train.train_transfer_module", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                "save/my_style_transfer_module_zero_lambdal1_1",
                "--dataset",
                "humanml",
                "--style_dataset",
                "bandai-2",
                "--overwrite",
                "--num_steps",
                "8_000",
                "--save_interval",
                "1_000",
                "--lr",
                "1e-4",
                "--train_platform_type",
                "TensorboardPlatform",
                "--zero_conv", 
                "--resume_checkpoint",
                "save/my_style_transfer_module_zero/model_pretrained.pt",
                "--lambda_l1",
                "1",
                "--lambda_bone",
                "0.1",
                "--log_interval",
                "100"
            ]
            
        },
        {
            "name": "Python: train_my_transfer_module_zero_lambda_0",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "train.train_transfer_module", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                "save/my_style_transfer_module_zero_lambdal1_0",
                "--dataset",
                "humanml",
                "--style_dataset",
                "bandai-2",
                "--overwrite",
                "--num_steps",
                "8_000",
                "--save_interval",
                "1_000",
                "--lr",
                "1e-4",
                "--train_platform_type",
                "TensorboardPlatform",
                "--zero_conv", 
                "--resume_checkpoint",
                "save/my_style_transfer_module_zero/model_pretrained.pt",
                "--lambda_l1",
                "0",
                "--lambda_bone", 
                "0.1",
                "--log_interval",
                "100"

            ]
            
        },
        {
            "name": "Python: train_my_transfer_module",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "train.train_transfer_module", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                "save/my_style_transfer_module",
                "--dataset",
                "humanml",
                "--style_dataset",
                "bandai-2",
                "--overwrite",
                "--num_steps",
                "8_000",
                "--save_interval",
                "1_000",
                "--lr",
                "1e-4",
                "--train_platform_type",
                "TensorboardPlatform",
            ]
            
        },
        {
            "name": "Python: my_motion_enc_512_fintune",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "train.fintune_motion_encoder", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                "save/my_motion_enc_512_finetune_encmdm_bandai-2_addtextloss",
                "--dataset",
                "humanml",
                "--style_dataset",
                "bandai-2",
                "--resume_checkpoint",
                "save/my_motion_enc_512",
                "--overwrite",
                "--num_steps",
                "80_000",
                "--save_interval",
                "10_000",
                "--lr",
                "1e-5",
                "--train_platform_type",
                "TensorboardPlatform",
            ]
            
        },
        {
            "name": "Python: predict_motion_trajectory",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "sample.predict_motion_trajectory", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--model_path",
                "save/my_motion_trajectory/model000050000.pt",
                "--num_samples",
                "5",
                "--seed",
                "10"
            ]
        },
        
        {
            "name": "Python: motion_reconstruction",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "sample.motion_reconstruction", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--motionenc_path",
                "save/my_motion_enc_512_finetune_encmdm_bandai-2_addtextloss/model000610161.pt",
                // "save/my_motion_enc_512_finetune_encmdm_bandai-2/model000600161.pt",
                "--num_samples",
                "5",
                "--seed",
                "1243"
            ]
        },
        {
            "name": "Python: train_motion_encoder",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "train.train_motion_encoder",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                "save/my_motion_enc_512",
                "--dataset",
                "humanml",
                "--overwrite",
                "--train_platform_type",
                "TensorboardPlatform",
                // "--resume_checkpoint",
                // "save/my_motion_enc_512"
            ]
        },

        {
            "name": "Python: train_motion_trajectory",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "train.train_motion_trajectory",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                "save/my_motion_trajectory",
                "--dataset",
                "humanml",
                "--overwrite",
                "--train_platform_type",
                "TensorboardPlatform",
                "--save_interval", 
                "10000"
            
            ]
        },

        {
            "name": "Python: eval_inpainting_style_example",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "sample.finetuned_motion_inpainting_style_example",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--model_path",
                "save/my_inpainting_style_model_regularization/model000000050.pt",
                "--num_samples",
                "1",
                "--input_text",
                // "'a figure skips in a circle.",
                "a figure skips in a circle",
                "--output_dir",
                "./save/my_inpainting_style_model_regularization/noised_example",
            ]
        },

        {
            "name": "Python: eval_inpainting_style_video",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "sample.motion_inpainting_style_from_video",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--model_path",
                // "save/my_inpainting_style_model_regularization_ddim20/outdoors_fencing_01/model000000766.pt",
                // "save/my_inpainting_style_model_regularization_ddim20/stealthily/model000000383.pt",
                // "save/my_inpainting_style_model_regularization_ddim20/walk_dog/model000000383.pt",
                // "save/my_inpainting_style_model_regularization_ddim20/cowboy/model000000383.pt",
                // "save/my_inpainting_style_model_regularization_ddim20/against_the_wind/model000000383.pt",
                // "save/my_inpainting_style_model_regularization_ddim20/against_the_wind_Ls100/model000000383.pt",
                // "save/my_inpainting_style_model_regularization_ddim20/against_the_wind_Ls001/model000000383.pt",
                // "save/my_inpainting_style_model_regularization_ddim20/against_the_wind_Ls001/model000000383.pt",

                // "save/my_inpainting_style_model_regularization_ddim20/sneak/model000000383.pt",
                // "save/my_inpainting_style_model_regularization_ddim20/zombie/model000000383.pt", 
                // "save/my_inpainting_style_model_regularization_ddim20/old/model000000383.pt", 
                // "save/my_inpainting_style_model_regularization_ddim20/sore_back/model000000383.pt",
                // "save/my_inpainting_style_model_regularization_ddim20/happily/model000000383.pt",
                "save/my_inpainting_style_model_regularization_ddim20/mocap_1/model000000383.pt",
                "--num_samples",
                // "64",
                "1",
                "--num_repetitions",
                "1",

                // "--input_text",
                // "A figure walks sideways",
                // "A man walks backwards",
                // "a man walks straight",
                // "a figure is walking alone in place",
                // "a person walks turning to the right.",
                // "a person walks then rest and continue walking.",
                // "a man walks to the right.",
                // "A man runs turn right normal",
                // "A person runs in a circle.",
                "--seed",
                "10",
                "--use_ddim",
                "1"
            ]
        },
        {
            "name": "Python: eval_inpainting_stylexia",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "sample.finetuned_motion_inpainting_style",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--model_path",
                // "save_stylexia/my_inpainting_style_model/350angry_jumping/model000000024.pt",
                // "save_stylexia/my_inpainting_style_model/012strutting_normal walking/model000000024.pt",
                // "save_stylexia/my_inpainting_style_model/001angry_normal walking_with_Ls/model000000024.pt",
                // "save_stylexia/my_inpainting_style_model/001angry_normal walking/model000000024.pt",
                "save_stylexia/my_inpainting_style_model/040depressed_normal walking/model000000032.pt",
                "--num_samples",
                "1",
                "--input_text",
                // "A man is normal walking neutral",
                // "A person is punching strutting",
                // "A person is normal walking old",
                // "A person is jumping depressed",
                // "A person is running depressed",
                "A person is kicking depressed",
                "--seed",
                "10",
                "--use_ddim",
                "1"
            ]
        },
        {
            "name": "Python: eval_inpainting_style_AIST",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "sample.finetuned_motion_inpainting_style",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--model_path",
                "save_AIST/my_inpainting_style_model/gJS_sBM_cAll_d01_mJS3_ch02/model000000075.pt",
                "--num_samples",
                "1",
                "--input_text",
                "A person is basic dancing inBreak style",
                "--seed",
                "10",
                "--use_ddim",
                "1"
            ]
        },
        {
            "name": "Python: eval_inpainting_style",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "sample.finetuned_motion_inpainting_style",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--model_path",
                "save/my_inpainting_style_model_regularization_ddim20/M008551/model000001149.pt",
                // "save_bandai/my_inpainting_style_model_regularization_ddim20/model000000135.pt",
                // "save_bandai/my_inpainting_style_model_regularization_clipspace_ddim20/model000000135.pt",
                // "save_bandai/my_inpainting_style_model/dataset-2_raise-up-both-hands_masculine_021/model000000135.pt",
                // "save_bandai_train/my_inpainting_style_model/dataset-2_raise-up-both-hands_masculine_021/model000000114.pt",
                // "save/my_inpainting_style_model_regularization_ddim20/skip_happy_best/model000000766.pt",
                // "save_bandai_train/my_inpainting_style_model/dataset-2_raise-up-left-hand_masculine_003/model000000114.pt",
                // "save_bandai_train_newtpose/my_inpainting_style_model/dataset-2_raise-up-left-hand_masculine_003/model000000114.pt",
                // "save_bandai_train_newtpose/my_inpainting_style_model/dataset-2_walk-turn-left_exhausted_010/model000000114.pt",
                // "save_bandai_train_newtpose/my_inpainting_style_model/dataset-2_walk_youthful_001/model000000114.pt",
                // "save_bandai_train_newtpose/my_inpainting_style_model/dataset-2_run_exhausted_015/model000000114.pt",

                "--num_samples",
                "1",
                "--input_text",
                // "A person standing in place lifts and waves with his right hand.",
                // "A person walks with both hands up.",
                // "A man runs turn right normal",
                // "A person raise up right hand normal",
                // "A person walks turn right feminine",
                // "A person runs feminine",
                // "A person walks masculine",
                // "A person walks exhausted",
                // "A figure waves left hand masculine",
                // "A man waves both hands youthful",
                "A man waves both hands exhausted",
                "--seed",
                "10",
                "--use_ddim",
                "1",
            ]
        },
        {
            "name": "Python: eval_inpainting_style_stylexia_unseen",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "sample.finetuned_motion_inpainting_style_stylexia_unseen",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--model_path",
                // "save/my_inpainting_style_model_regularization_ddim20/021old_normal walking/model000000383.pt",
                // "save/my_inpainting_style_model_regularization_ddim20/021old_normal walking_Ls01/model000000383.pt",
                // "save/my_inpainting_style_model_regularization_ddim20/025proud_normal walking/model000000383.pt",
                // "save/my_inpainting_style_model_regularization_ddim20/025proud_normal walking_Ls01/model000000383.pt",

                // "save/my_inpainting_style_model_regularization_ddim20/025proud_normal walking_Ls003/model000000383.pt",
                // "save/my_inpainting_style_model_regularization_ddim20/025proud_normal walking_Ls0005/model000000383.pt",
                // "save/my_inpainting_style_model_regularization_ddim20/025proud_normal walking_Ls100/model000000383.pt",
                // "save/my_inpainting_style_model_regularization_ddim20/025proud_normal walking_Ls500/model000000383.pt",
                // "save/my_inpainting_style_model_regularization_ddim20/047sexy_normal walking/model000000383.pt",
                "save/my_inpainting_style_model_regularization_ddim20/047sexy_normal walking_Ls01/model000000383.pt",
                // "save/my_inpainting_style_model_regularization_ddim20/134depressed_normal walking/model000000383.pt",
                // "save/my_inpainting_style_model_regularization_ddim20/286depressed_running/model000000383.pt",
                // "save/my_inpainting_style_model_regularization_ddim20/286depressed_running_Ls200/model000000383.pt",
                // "save/my_inpainting_style_model_regularization_ddim20/286depressed_running_Ls100/model000000383.pt",
                // "save/my_inpainting_style_model_regularization_ddim20/042depressed_normal walking/model000000383.pt",
                // "save/my_inpainting_style_model_regularization_ddim20/355childlike_jumping/model000000383.pt",
                // "save/my_inpainting_style_model_regularization_ddim20/007childlike_normal walking/model000000383.pt",
                // "save/my_inpainting_style_model_regularization_ddim20/007childlike_normal walking_Ls01/model000000383.pt",

                "--num_samples",
                "1",
                // "--input_text",
                // "A person kicks.",
                // "A person kicks twice.",
                // "A person walks with both hands up.",
                // "A man runs turn right normal",
                // "A person raise up right hand normal",
                // "A person walks turn right feminine",
                // "A person runs feminine",
                // "A person walks masculine",
                // "A figure waves left hand masculine",
                "--seed",
                "10",
                "--use_ddim",
                "1",
                "--num_repetitions",
                "1",
                "--batch_size",
                "1",
                // "1",
                
            ]
        },
        {
            "name": "Python: eval_horizontal_inpainting",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "sample.finetuned_motion_control",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--model_path",
                "save/my_inpainting_model/model000050000.pt",
                "--num_samples",
                "1",
                "--is_using_data",
                "0",
                "--input_text",
                "a person walks"
            ]
        },
        {
            "name": "Python: rec_input_output",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "sample.re_input_output",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--model_path",
                "save/finetune_style100_middle_dispart_style_debug/model000600161.pt",
                "--num_samples",
                "5",
                "--seed",
                "15",
                "--style_dataset",
                "bandai-2",
            ]
        },
        {
            "name": "Python: vis_adain_para",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "sample.visulize_hidden",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--model_path",
                "save/finetune_style100_middle/model000631161.pt",
                "--num_samples",
                "30",
                "--seed",
                "10"
            ]
        },
        {
            "name": "Python: sample_style_tranfer",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "sample.style_transfer",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--model_path",
                "save/finetune_style100_middle/model000631161.pt",
                "--num_samples",
                "5",
                "--num_repetitions",
                "3",
                "--seed",
                "10"
            ]
        },
        {
            "name": "Python: train_style_finetune",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            // "program": "${command:python.interpreterPath}",
            "module": "train.train_style_finetune",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                "save/finetune_style100_middle_dispart_style_debug",
                "--dataset",
                "humanml",
                "--style_dataset",
                "style100",
                "--resume_checkpoint",
                "save/my_humanml_trans_enc_512",
                "--overwrite",
                "--lambda_sty_cons",
                "1",
                "--lambda_sty_trans",
                "1",
                "--lambda_cont_pers",
                "1",
                "--lambda_cont_vel",
                "1",
                "--lambda_diff_sty",
                "1",
                "--num_steps",
                "80_000",
                "--save_interval",
                "1_000",
                "--lr",
                "1e-5",
                "--train_platform_type",
                "TensorboardPlatform",
                "--middle_trans"
            ]
        },
        
        {
            "name": "Python: sample_t2m_humanml",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            // "program": "${command:python.interpreterPath}",
            "module": "sample.generate",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--model_path",
                "./save/my_humanml_trans_enc_512/model000200000.pt",
                // "./save_stylexia/my_inpainting_model/model000050000.pt",
                "--dataset",
                "humanml",
                // "stylexia_posrot",
                "--text_prompt",
                // "A person walks turn right feminine"
                // "A man is running childlike"
                "A person walks turning right.",
                "--seed", 
                "30"
                
            ]
        },
        {
            "name": "Python: sample_t2m_AIST",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            // "program": "${command:python.interpreterPath}",
            "module": "sample.generate",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--model_path",
                // "./save/my_humanml_trans_enc_512/model000050000.pt",
                "./save_AIST/my_inpainting_model/model000100000.pt",
                "--dataset",
                // "humanml",
                "AIST_posrot",
                "--text_prompt",
                // "A person walks turn right feminine"
                "A man is basic dancing in Lock style",
                "--seed", 
                "200"
                
            ]
        },
        {
            "name": "Python: vis motion and clip tsne",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            // "program": "${command:python.interpreterPath}",
            "module": "sample.tsne_vis_style",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--model_path",
                "./save_bandai/my_motion_enc_512/model000004545.pt"
            ]
        },
        {
            "name": "Python: eval_metric_stylexia",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "eval.generate_eval_data", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                "eval_results/stylexia_correct_Ls", 
                "--dataset",
                "stylexia_posrot",
                "--overwrite",
                "--num_steps",
                "16",
                "--lr",
                "1e-4",
                "--resume_checkpoint",
                "save_stylexia/my_inpainting_style_model/model_pretrained.pt",
                "--log_interval",
                "15",    
                "--inpainting_mask",
                "root_horizontal", 
                "--diffusion_steps",
                "1000",
                "--skip_steps",
                "700",
                "--batch_size",
                "64",
                "--weakly_style_pair",
                "1",
                "--use_ddim",
                "1",
                "--mdm_path",
                "./save_stylexia/my_inpainting_model/model000050000.pt",
                "--motion_enc_path",
                "./save_stylexia/my_motion_enc_512/model000004504.pt",
                "--inpainting_model_path", 
                "mdm_model is inpainting_model in this case.",
            ]
        },
        {
            "name": "Python: eval_metric_stylexia_ae_ablation",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "eval.generate_eval_data_stylexia_ae_ablation", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                "eval_results/stylexia_ae", 
                "--dataset",
                "stylexia_posrot",
                "--overwrite",
                "--num_steps",
                "16",
                "--lr",
                "1e-4",
                "--resume_checkpoint",
                "save_stylexia_ablation/model000004504.pt",
                "--log_interval",
                "15",    
                "--inpainting_mask",
                "root_horizontal", 
                "--diffusion_steps",
                "1000",
                "--skip_steps",
                "700",
                "--batch_size",
                "64",
                "--weakly_style_pair",
                "1",
                "--use_ddim",
                "1",
                "--mdm_path",
                "./save_stylexia/my_inpainting_model/model000050000.pt",
                "--motion_enc_path",
                "./save_stylexia/my_motion_enc_512/model000004504.pt",
                "--inpainting_model_path", 
                "mdm_model is inpainting_model in this case.",
            ]
        },
        {
            "name": "Python: eval_metric_stylexia_dis_ablation",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "eval.generate_eval_data_stylexia_dis_ablation", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                "eval_results/stylexia_dis", 
                "--dataset",
                "stylexia_posrot",
                "--overwrite",
                "--num_steps",
                "16",
                "--lr",
                "1e-4",
                "--resume_checkpoint",
                "save_stylexia/my_inpainting_style_model/model_pretrained.pt",
                "--log_interval",
                "15",    
                "--inpainting_mask",
                "root_horizontal", 
                "--diffusion_steps",
                "1000",
                "--skip_steps",
                "700",
                "--batch_size",
                "64",
                "--weakly_style_pair",
                "1",
                "--use_ddim",
                "1",
                "--mdm_path",
                "./save_stylexia/my_inpainting_model/model000050000.pt",
                "--motion_enc_path",
                "./save_stylexia/my_motion_enc_512/model000004504.pt",
                "--inpainting_model_path", 
                "./save_stylexia_ablation_dis/model000002000.pt",
            ]
        },
        {
            "name": "Python: eval_metric_bandai",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "eval.generate_eval_data_bandai", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                "eval_results/bandai_correct_Ls", 
                "--dataset",
                "bandai-2_posrot",
                "--overwrite",
                "--num_steps",
                "90",
                "--lr",
                "1e-4",
                "--resume_checkpoint",
                "save_bandai_train/my_inpainting_style_model/model_pretrained.pt",
                "--log_interval",
                "15",    
                "--inpainting_mask",
                "root_horizontal", 
                "--diffusion_steps",
                "1000",
                "--skip_steps",
                "700",
                "--batch_size",
                "64",
                "--weakly_style_pair",
                "1",
                "--use_ddim",
                "1",
                "--mdm_path",
                "./save_bandai_train/my_inpainting_model_new/model000100000.pt",
                "--motion_enc_path",
                "./save_bandai_train/my_motion_enc_512/model000004522.pt",
                "--inpainting_model_path", 
                "mdm_model is inpainting_model in this case.",
            ]
        },
        {
            "name": "Python: eval_metric_bandai_ablation",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "eval.generate_eval_data_bandai_ablation", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                "eval_ablation/bandai_K200", 
                "--dataset",
                "bandai-2_posrot",
                "--overwrite",
                "--num_steps",
                "90",
                "--lr",
                "1e-4",
                "--resume_checkpoint",
                "save_bandai_train/my_inpainting_style_model/model_pretrained.pt",
                "--log_interval",
                "15",    
                "--inpainting_mask",
                "root_horizontal", 
                "--diffusion_steps",
                "1000",
                "--skip_steps",
                "800",
                "--batch_size",
                "64",
                "--weakly_style_pair",
                "1",
                "--use_ddim",
                "1",
                "--mdm_path",
                "./save_bandai_train/my_inpainting_model_new/model000100000.pt",
                "--motion_enc_path",
                "./save_bandai_train/my_motion_enc_512/model000004522.pt",
                "--inpainting_model_path", 
                "mdm_model is inpainting_model in this case.",
            ]
        },
        {
            "name": "Python: eval_neutral_bandai",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "eval.generate_neutral_data_bandai", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--save_dir",
                "./eval_neutral/bandai_noise1000_wotrajectory", 
                "--dataset",
                "bandai-2_posrot",
                "--overwrite",
                "--num_steps",
                "90",
                "--lr",
                "1e-4",
                "--resume_checkpoint",
                "save_bandai_train/my_inpainting_style_model/model_pretrained.pt",
                "--log_interval",
                "15",    
                "--inpainting_mask",
                // "root_horizontal", 
                "none",
                "--diffusion_steps",
                "1000",
                "--skip_steps",
                "700",
                "--batch_size",
                "64",
                "--weakly_style_pair",
                "1",
                "--use_ddim",
                "0",
                "--mdm_path",
                "./save_bandai_train/my_inpainting_model_new/model000100000.pt",
                "--motion_enc_path",
                "./save_bandai_train/my_motion_enc_512/model000004522.pt",
                "--inpainting_model_path", 
                "mdm_model is inpainting_model in this case.",
            ]
        },

        {
            "name": "Python: eval_motion_clip_score",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "eval.cal_clip_score", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--model_path",
                "save_bandai_train/my_inpainting_style_model/dataset-2_raise-up-both-hands_masculine_021/model000000114.pt",
                "--dataset",
                "bandai-2_posrot",
                "--inpainting_mask",
                "root_horizontal", 
                "--skip_steps",
                "900",
                "--batch_size",
                "64",
                "--weakly_style_pair",
                "1",
                "--mdm_path",
                "./save_bandai_train/my_inpainting_model_new/model000100000.pt",
                "--motion_enc_path",
                "./save_bandai_train/my_motion_enc_512/model000004522.pt",
                "--inpainting_model_path", 
                "mdm_model is inpainting_model in this case.",
            ]
        },
        {
            "name": "Python: user_study",
            "type": "python",
            "request": "launch",
            // "program": "${file}",
            "module": "eval.generate_user_study", //finetune the motion encoder on the style motion dataset
            "console": "integratedTerminal",
            "justMyCode": true,
        }

    ]
}